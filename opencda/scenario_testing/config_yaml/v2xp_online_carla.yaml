description: |-
  Copyright 2021 <UCLA Mobility Lab>
  Author: Runsheng Xu <rxx3386@ucla.edu>
  Content: This is the scenario testing configuration file for single vehicle perception/localization/behavior/control
           testing in high speed in the customized 2lanefree simple version.


# define carla simulation setting
world:
  sync_mode: true
  client_port: 2000
  fixed_delta_seconds: &delta 0.05
  seed: 22
  weather:
    sun_altitude_angle: 15 # 90 is the midday and -90 is the midnight
    cloudiness: 0 # 0 is the clean sky and 100 is the thickest cloud
    precipitation: 0 # rain, 100 is the heaviest rain
    precipitation_deposits: 0 # Determines the creation of puddles. Values range from 0 to 100, being 0 none at all and 100 a road completely capped with water.
    wind_intensity: 0 # it will influence the rain
    fog_density: 0 # fog thickness, 100 is the largest
    fog_distance: 0  # Fog start distance. Values range from 0 to infinite.
    fog_falloff: 0 # Density of the fog (as in specific mass) from 0 to infinity. The bigger the value, the more dense and heavy it will be, and the fog will reach smaller heights
    wetness: 0

# Define settings for multi-class blueprint spawning
# Comment out this chunk of code or set use_multi_class_bp to be False if you don't want to spawn multi-class actors
blueprint:
  use_multi_class_bp: true
  bp_meta_path: "opencda/assets/blueprint_meta/bbx_stats_0912.json" # Define the path for loading the blueprint metadata for defining the class of each blueprint
  # Define blueprint type sample probabilities
  bp_class_sample_prob:
    car: 0.5
    truck: 0.1
    bus: 0.1
#    bicycle: 0.1
#    motorcycle: 0.1

# Define the basic parameters of the rsu
rsu_base: &rsu_base
  sensing:
    perception:
      activate: true # when not activated, objects positions will be retrieved from server directly
      coperception: true
      enable_communicate: true
      enable_show_gt: false
      camera_visualize: 1 # how many camera images need to be visualized. 0 means no visualization for camera
      camera_num: 4 # how many cameras are mounted on the vehicle. Maximum 3(frontal, left and right cameras)
      lidar_visualize: true # whether to visualize lidar points using open3d
      lidar: # lidar sensor configuration, check CARLA sensor reference for more details
        channels: 64
        range: 120
        points_per_second: 1300000
        rotation_frequency: 20 # the simulation is 20 fps
        upper_fov: 2
        lower_fov: -25
        dropoff_general_rate: 0.1
        dropoff_intensity_limit: 0.7
        dropoff_zero_intensity: 0.15
        noise_stddev: 0.02
    localization:
      activate: false # when not activated, ego position will be retrieved from server directly
      dt: *delta # used for kalman filter
      gnss: # gnss sensor configuration
        noise_alt_stddev: 0.05
        noise_lat_stddev: 3e-6
        noise_lon_stddev: 3e-6

# Define the basic parameters of the vehicles
vehicle_base: &vehicle_base
  sensing: &base_sensing
    perception: &base_perception
      activate: true # when not activated, objects positions will be retrieved from server directly
      coperception: true # cooperative perception
      enable_communicate: true
      enable_show_gt: false
      camera_visualize: 1 # how many camera images need to be visualized. 0 means no visualization for camera
      camera_num: 4 # how many cameras are mounted on the vehicle. Maximum 3(frontal, left and right cameras)
      lidar_visualize: true # whether to visualize lidar points using open3d
      lidar: # lidar sensor configuration, check CARLA sensor reference for more details
        channels: 64
        range: 120
        points_per_second: 1000000
        rotation_frequency: 20 # the simulation is 20 fps
        upper_fov: 2
        lower_fov: -25
        dropoff_general_rate: 0.3
        dropoff_intensity_limit: 0.7
        dropoff_zero_intensity: 0.4
        noise_stddev: 0.02
    localization: &base_localize
      activate: false # when not activated, ego position will be retrieved from server directly
      coperception: false # cooperative perception
      dt: *delta # used for kalman filter
      gnss: # gnss sensor configuration
        noise_alt_stddev: 0.005
        noise_lat_stddev: 1e-6
        noise_lon_stddev: 1e-6
        heading_direction_stddev: 0.1 # degree
        speed_stddev: 0.2
      debug_helper: &loc_debug_helper
        show_animation: false # whether to show real-time trajectory plotting
        x_scale: 1.0 # used to multiply with the x coordinate to make the error on x axis clearer
        y_scale: 100.0 # used to multiply with the y coordinate to make the error on y axis clearer
  map_manager: &base_map_manager
    pixels_per_meter: 2
    raster_size: [ 224, 224 ]
    lane_sample_resolution: 0.1
    visualize: false
    activate: false
  behavior: &base_behavior
    max_speed: 30 # maximum speed, km/h
    tailgate_speed: 34 # when a vehicles needs to be close to another vehicle asap
    speed_lim_dist: 3 # max_speed - speed_lim_dist = target speed
    speed_decrease: 15 # used in car following mode to decrease speed for distance keeping
    safety_time: 4 # ttc safety thresholding for decreasing speed
    emergency_param: 0.4 # used to identify whether a emergency stop needed
    ignore_traffic_light: true # whether to ignore traffic light
    overtake_allowed: false # whether overtake allowed, typically false for platoon leader
    collision_time_ahead: 1.5 # used for collision checking
    overtake_counter_recover: 35 # the vehicle can not do another overtake during next certain steps
    sample_resolution: 4.5 # the unit distance between two adjacent waypoints in meter
    local_planner: &base_local_planner # trajectory planning related
      buffer_size: 12 # waypoint buffer size
      trajectory_update_freq: 15 # used to control trajectory points updating frequency
      waypoint_update_freq: 9 # used to control waypoint updating frequency
      trajectory_dt: 0.20 # for every dt seconds, we sample a trajectory point from the trajectory path as next goal state
      min_dist: 3 # used to pop out the waypoints too close to current location
      debug: false # whether to draw future/history waypoints
      debug_trajectory: false # whether to draw the trajectory points and path
  controller: &base_controller
    type: pid_controller # this has to be exactly the same name as the controller py file
    args:
      lat:
        k_p: 0.75
        k_d: 0.02
        k_i: 0.4
      lon:
        k_p: 0.37
        k_d: 0.024
        k_i: 0.032
      dynamic: false # whether use dynamic pid setting
      dt: *delta # this should be equal to your simulation time-step
      max_brake: 1.0
      max_throttle: 1.0
      max_steering: 0.3
  v2x: &base_v2x # communication related
    enabled: true
    communication_range: 70
    loc_noise: 0.0
    yaw_noise: 0.0
    speed_noise: 0.0
    lag: 0


# define the background traffic control by carla
carla_traffic_manager:
  sync_mode: true # has to be same as the world setting
  global_distance: 5 # the minimum distance in meters that vehicles have to keep with the rest
  # Sets the difference the vehicle's intended speed and its current speed limit.
  #  Carla default speed is 30 km/h, so -100 represents 60 km/h,
  # and 20 represents 24 km/h
  global_speed_perc: -10
  set_osm_mode: true # Enables or disables the OSM mode.
  auto_lane_change: true
  random: true # whether to random select vehicles' color and model
  ignore_lights_percentage: 100 # whether set the traffic ignore traffic lights
  vehicle_list: ~  # a number or a list
  # Used only when vehicle_list is a number.
  #  x_min, x_max, y_min, y_max, x_step, y_step, vehicle_num
  range:
    - [-11, 12, 100, 200, 3.5, 15, 25]


# define scenario. In this scenario, a 4-vehicle platoon already exists.
scenario:
#  rsu_list:
#    - <<: *rsu_base
#      spawn_position: [12.00, 192.31, 3.0]
#      id: -1

  single_cav_list:
    - <<: *vehicle_base
      spawn_position: [12.00, 192.31, 0.3, 0, -90, 0]
      destination: [67.12, 150.2, 1.0]
      v2x:
        <<: *base_v2x
        communication_range: 70
      behavior:
        <<: *base_behavior
        local_planner:
          <<: *base_local_planner
          debug_trajectory: false
          debug: false
    - <<: *vehicle_base
      spawn_position: [-5.51, 160.24, 0.3, 0, 90, 0]
      destination: [-2.43, 263, 0.3]
      v2x:
        <<: *base_v2x
        communication_range: 70
      behavior:
        <<: *base_behavior
        local_planner:
          <<: *base_local_planner
          debug_trajectory: false
          debug: false

# these are parameters supporting cooperative perception
# models are pending to be added with all the models supported in the intermediate fusion
coperception:
  models:
    early: 'opencood/logs/pointpillar_early_fusion'
    intermediate_v2xvit: 'opencood/logs/pointpillar_v2xvit_fusion'
    intermediate_attentive: 'opencood/logs/pointpillar_attentive_fusion'
    intermediate_cobevt: 'opencood/logs/pointpillar_cobevt_fusion'
    late: 'opencood/logs/pointpillar_late_fusion'
  fusion_method: 'intermediate_v2xvit'
